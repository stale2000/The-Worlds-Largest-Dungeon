# World's Largest Dungeon RAG Server

RAG server for World's Largest Dungeon and D&D 5.2 SRD - vector search with 1940 indexed chunks

## Quick Start

```bash
npm install
npm run build
npm start
```

## Index Stats

| Metric | Count |
|--------|-------|
| Sources | 2 |
| Chunks | 1940 |
| Vectors | 1940 |
| Embedding Model | openai/text-embedding-3-small |

## Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `PORT` | No | HTTP server port (default: 8080) |
| `OPENAI_API_KEY` | For /chat | OpenAI API key for chat endpoint |
| `OPENAI_MODEL` | No | Model for chat (default: gpt-5-nano-2025-08-07) |

## Deploy to Railway

1. Push to GitHub
2. Connect repo to Railway
3. Add `OPENAI_API_KEY` environment variable (for /chat)
4. Deploy

## HTTP Endpoints

### Health Check
```bash
curl https://your-app.railway.app/health
```

### Search
```bash
curl -X POST https://your-app.railway.app/search \
  -H "Content-Type: application/json" \
  -d '{"query": "your search query", "mode": "keyword", "top_k": 10}'
```

### Chat (RAG + LLM)
```bash
curl -X POST https://your-app.railway.app/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "What is...?"}'
```

### List Sources
```bash
curl https://your-app.railway.app/sources
```

## MCP Integration

Add to your MCP client config:
```json
{
  "mcpServers": {
    "wld-rag-server": {
      "command": "node",
      "args": ["path/to/dist/index.js"]
    }
  }
}
```

---
*Generated by IndexFoundry*
